This file contains instructions for running the code on any system. We ran it on a server provided to us which has Intel Xeon processor and Nvidia Tesla K40c as well as GeForce GT 610 graphics card. Naturally our tensorflow and tflearn libraries take advantage of the same.
On such a system it was observed that it takes about 15 minutes to train the Neural Network. Keep in mind that this time has been clocked for training with 1000 training images and 100 validation images or 128 x 128 resolution. 
To run this code you need to populate the "Testing" and "Training" folders with your testing and training images respectively. So for example in our case the 100 validation images would go into the folder "Testing" and then be populated into the "Positive" and "Negative" folders of "Testing" respectively. Same would go for the training images. 
After populating the above folders and installing all the libraries on your system the "creator.py" should be executed first followed by "trainer.py" and "predictor.py". "creator.py" creates "training.txt" and "validation_test.txt" which allows the "trainer.py" to create the h5py dataset and train the neural net. "predictor.py" then is able to give the predicted output. 
The "training.txt" file contains the path of the images followed by the label to which that image belongs. So training.txt would contain:
../Dataset/Training/Positive/1.jpg 0

This is assuming the positive images belong to class named "0". Yes, there is a space between the path and the label. The text file for the testing folder will also have a similar format. Using these two text files h5py will know where to look for the images and their corresponding labels and will construct the dataset accordingly. At the moment we have only "Positive" and "Negative" folders since we have only two classes. You can choose to put any number of folders corresponding to the number classes you have. We have also included a Makefile so the user of this code can just execute the make file and see the output for themselves.
